{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# veriyi okumak icin yapilacak islemler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN_notebook3 te var islemler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data= '/content/drive/MyDrive/DataSets/cell_images'\n",
    "#colab'ta veri dosyasina ulasirken\n",
    "# content demek ilk dosya simgesine tikladigin yer, ordan drive tikliyorsun altinda myDrive geliyor ve sonrasini yaziyorsun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# veriyi tanimak icin yapilacak islemler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]  \n",
    " #buda bizim datamizin outputlari\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(25, 25))\n",
    "for i in range(256):  #renkler 0,255 arasindaydi, 256 dahil olmuyor zaten\n",
    "    rand_index = int(np.random.randint(low=0, high=50000, size=1))  #yukarida aciklamasi var,asagidaki resimlerin randomolarak alinmasi icin\n",
    "    plt.subplot(16, 16, i+1, label=classes[int(y_train[rand_index])])  #16ya 16 lik asagida resimler var\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[int(y_train[rand_index])])\n",
    "    plt.imshow(X_train[rand_index])   #imshow biseyin gösterilmesi demek\n",
    "\n",
    "    #bu bizim datamizdan bir bölüm gifi df.head() gibi bisey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.reshape(x_train.shape[0],x_train.shape[1],1) \n",
    "\n",
    "#bu kod ile reshape yapabiliriz diye yaziyordu stackoverflow da "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit ve sonrasi icin hazir kod blogu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Function to Train & Test  given model (Early Stopping monitor 'val_loss')\n",
    "def train_test(model, X_train, y_train , \n",
    "               X_test, \ty_test, epochs=100, \n",
    "\t\t\t\t\t\t\t        verbose=0, patience=5):\n",
    "\t# patient early stopping\n",
    "\t#es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=1, patience=20)\n",
    "\tes = EarlyStopping(monitor='val_loss', mode='min', \n",
    "\t                   verbose=1, patience=patience)\n",
    "\t# train model\n",
    "\tprint('training for ',epochs,\n",
    "\t      ' epochs begins with',\n",
    "\t\t\t\t' EarlyStopping(monitor= val_loss ',\n",
    "\t\t\t\t' patience=',patience,')....')\n",
    "\thistory=model.fit(X_train, y_train, validation_split= 0.1, epochs=epochs,  verbose=verbose, callbacks=[es])\n",
    "\tprint(epochs,' epoch training finished...')\n",
    "\n",
    "\t# report training\n",
    "\t# list all data in history\n",
    "\t#print(history.history.keys())\n",
    "\t# evaluate the model\n",
    "\t_, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
    "\t_, test_acc = model.evaluate(X_test, \ty_test, verbose=0)\n",
    "\tprint('\\nPREDICTION ACCURACY (%):')\n",
    "\tprint('Train: %.3f, Test: %.3f' % (train_acc*100, test_acc*100))\n",
    "\t# summarize history for accuracy\n",
    "\tplt.plot(history.history['accuracy'])\n",
    "\tplt.plot(history.history['val_accuracy'])\n",
    "\tplt.title(model.name+' accuracy')\n",
    "\tplt.ylabel('accuracy')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'val'], loc='upper left')\n",
    "\tplt.show()\n",
    "\t# summarize history for loss\n",
    "\tplt.plot(history.history['loss'])\n",
    "\tplt.plot(history.history['val_loss'])\n",
    "\tplt.title(model.name+' loss')\n",
    "\tplt.ylabel('loss')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'val'], loc='upper left')\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\t# spot check some examples\n",
    "\tprint('some examples...')\n",
    "\tfor _ in range(10):\n",
    "\t\tX,y = get_reversed_pairs(n_timesteps, n_features)\n",
    "\t\tyhat = model.predict(X, verbose=0)\n",
    "\t\tprint('Input',one_hot_decode(X[0]),\n",
    "\t\t\t\t\t'Expected:', one_hot_decode(y[0]), \n",
    "\t\t\t\t\t\t'Predicted', one_hot_decode(yhat[0]),\n",
    "\t\t\t\t\t\t\t'', array_equal(one_hot_decode(y[0]), one_hot_decode(yhat[0])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test(model_Single_LSTM_default_output, \n",
    "           X_train, y_train , X_test, y_test, \n",
    "           verbose=0)\n",
    "\n",
    "           #yukardaki kodu cagirmak iicnde bu formatta cagiriyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teorik Bilgiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genel Bilgiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DL ile ilgili genel bilgiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIAS # model calisirken input degerleri ile noro icin üretilmis weight degeri ile carpiliyor ve ve her bir noron icin bir BIAS degeri ekleniyor,\n",
    "     # bu carpma islemi ve bias eklendikten sonra cikan sonuc bir sonraki input icin girdi olarak giriyor\n",
    "     # dropout = durumuna göre hangi input bilgisinin bir sonraki norina aktarilacagi belirleniyor\n",
    "     # dropout noronlari random olrak kapatip aciyor,\n",
    "     # bu deger galiba eger hata orani fazla veya az cikarsa kendini ona göre degistiriyor\n",
    "#burdaki amacimiz en az hatayi yaptiracak weight ve bias degerlerini bulmak     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2023-01-11-12-10-36.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# burda sunu görüyorum inputlardan gelen degerlerin herbiri  random gelen agirlik degerleriyle carpiliyor ve bizim kurdugumuz hidden layer'in ilk npronuna \n",
    "# her inputtan bir tane geliyor, gelirken kendi getirdigi carpilmis degerle geliyor ve bu yeni noronda gelen tüm deger bu yeni bos noronda toplaniyor burda \n",
    "# burda ona bias degeri ekleniyor ve bu bos norona model kurarken atadigimiz activation functiona göre degerlendirilip bir autput cikariyor\n",
    "# bu output bir sonraki norona giderken input olrak giriyor\n",
    "# bu bir sonraki noronda da benzer islemler yapiliyor bir öncekinin outputlari gelip tekrardan belli bir weight degerleriyle carpilip, toplandiktan sonra \n",
    "#  bias ekleniyor ve yine o layerdaki functiona göre degerlendiriliyor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification ile bilgiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iki class'i birbirinden ayiriyorsan bunun adi binary classification denir \n",
    "# genelde bu tarz olanlar 0 ve 1 olarak ayrilir, aradigin sey 1 olarak nitelendiriyoruz,ki onu bulalim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imbalance Datalarda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalance datalarda asagilarda class_weight var, onu yapinca recall yükseliyor\n",
    "stratify=y   #imbalance,data oldugu icin,test ve trainde de ayni oran olmasi icin ugrasiyor,cünkü nasil ögrendiyse ona uygun tahmin yapsin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DL de de pipeline var, ama bu örneklerde yok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling ile ilgile bilgiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler() # Deep Learning de MinMax kullanmak daha iyidir diye bir bilgi gördüm\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler  # RobustScaler()\n",
    "\n",
    "# If there are too many outliers in the data, robust scaler should be used, otherwise minmax can be used.\n",
    "#datanin icinde cok fazla outlier varsa Robustscaler kullanilmasi daha iyi olur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X_train)\n",
    "X_train = scaler.fit_transform(X_train) #sadece train setine fit transform yapiyoruz\n",
    "X_test = scaler.transform(X_test)  #teste sadece transform\n",
    "\n",
    "# x test fit edilmedigi icin scalinge katilmiyor,ve trainin max degerinden fazla olanlar 1den büyük scale degerleri aliyor\n",
    "#fit matematiksel hesaplamaları yapıyor transform uyguluyor\n",
    "\n",
    "\n",
    "# bir noteboo'ta su sekilde degerler aldik\n",
    "X_train.max()= 1.0\n",
    "X_train.min()=0.0\n",
    "\n",
    "X_test.max() = 1.657\n",
    "X_test.min()= -0.23 \n",
    "\n",
    "# burdan sunu anliyoruz traine göre scaling islemi yapiliyor ve test datasina transform ederken maxtan büük degerle 1den büyük degerler alabiliyor\n",
    "# kücük olan degerler ise eksili degerler aliyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test split ile ilgili bilgiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['feature1', 'feature2']].values  # Önemli! array olarak vereceğiz data setini df olarak vermiyoruz bu nedenle .values ile değerleri alıyoruz\n",
    "y = df['price'].values\n",
    "\n",
    "#values diye bisey geldi,unun sebebi DL te array olarak verecegiz datayi, DataFrame olarak degil\n",
    "# bu values islemini train_test split isleimi yapacagi zaman veriyor ama ben kendi calismamda vermedim yinede calisti, bir ara baksam iyi olabilir,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42) \n",
    "#DL de de bu sekilde ayirma islemi yapabiliyorum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model kurma ile ilgili bilgiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential API ile Functional API arasindaki fark\n",
    "# sequential API ya her bir norona bir tane girdi giriyor ve bir tane cikti cikiyor, \n",
    "# ama Functional API da bir norondan return_state ve return_sequential parametrelerin True olup olmamasina bagli olarak her bir nörondan cikan output sayisi degisiyor\n",
    "# Functional API da ekstradan üretilen hidden_state ve Cell_state ler bu bilginin nerden kaldigini bir sonrakine göstermesi icin aktariliyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#burda asagida bir model kurma ve genel bilgleri görüyoyruz\n",
    "\n",
    "#aslinda iki asamadan olusuyor model Kurma ve model.compile asamasi bunlarda  \n",
    "# compile asamasinda modelin nasil calisacagini söylüyoruz\n",
    "\n",
    "model = Sequential()   \n",
    " # birbiri ardina gelen layerlari olusturuyor buna Sequential API diyoruz.\n",
    "\n",
    " \n",
    "\n",
    " #  bunun birde LSTM de Functional API kismi var oda bir layerden bir tek cikti degil return_sequence ve return_state'e göre 3 ciktida alabiliyor, \n",
    " # burda LSTM de funtional API da, return_state parametresi sayesinde burdaki cikti(hidden state) bir sonraki LSTM layer'a input olarak giriyor ve \n",
    " # diger üretilmis olan hidden state ve cell state ise bu bilginin kaldigi yeri göstermesi acisindan bilgi aktarimi yapiyor\n",
    " # önceki layerdan gelen bilgilerin üzerine insa ediyor, ve bilginin devami oluyor\n",
    "\n",
    "\n",
    "-------------------------------------------\n",
    "-Model kurma önemli notlar\n",
    "# model kurulurken kullangimiz parametreler activation function olarak = relu ve tanh functionlari kullaniyoruz\n",
    "# model kurmanin en son layer'inda ise eger bir linear output varsa Dense(units=1, activation= birsey yazmiyoruz, otomatikmen linear regression tipinde oluyor\n",
    "# eger modelimizde target featueres 0 ve 1 gibi degerler aliyorsa, burda output Dense(units=1) veriyoruz ve activation function olarakta sigmoid yaziyoruz\n",
    "# eger modelimiz minist data set gibi cikti olarak 0dan 9 a kadar olan sayilardan biri cikma ihtimali varsa o zaman Dense(units=3 veya 10) veriyoruz \n",
    "# ve ozaman activation='softmax' veriyoruz\n",
    "\n",
    "-----------------------------------------\n",
    "-Compile önemli notlar\n",
    "# bu asamada modelin hangi kriterlere göre modeli calistiracagina bakiyoruz\n",
    "# optimizer =büyük verilerde 'adam' iyi calisir kücük verilerde mse güzel calsiyor\n",
    "\n",
    "# @@@ multiclass problemlerde  -optimizer 'adam' veye 'rmsprop' \n",
    "#                              -loss='categorical_crosentropy'\n",
    "#                              -metrics='accuracy'  burda accuracy mantikli categorical oldugu icin do categoriyi bildi mi bilmedi mi na bakiyoruz, eger bildiyse dogru bilme oranlari önemli bu yüzden accuracy e bakilabilir\n",
    "#                              kullanilmasi tavsiye edilir, \n",
    "\n",
    "\n",
    "# @@@ binaryy problemlerde   -optimizer = 'adam' veya 'rmsprop' kullaniliyor\n",
    "#                            -loss = 'binary_crosentropy'\n",
    "#                            -metrics='accuracy' kullanilmasi tavsiye edilir                          \n",
    "\n",
    "# @@@ regression problemlerinde  -optimizer= 'adam' veya 'rmsprop' \n",
    "#                                -loss='mse' kullanilmasi tavsiye edilir\n",
    "\n",
    "-----------------------------------------\n",
    "\n",
    "model.add(Dense(units= 16, activation=\"relu\"))  #16 nöronlu katman, burda 2 nin katmanlari olarak degerler vermemize tavsiye ediliyor\n",
    "model.add(Dense(8, activation=\"relu\"))      # relu yerine baska biseyde secebilecektik\n",
    "model.add(Dense(1, activation=\"sigmoid\"))   # burda nizim datamizda iki tane cikti alabilecegi icin activation function sigmoid oluyor\n",
    "                                            # eger birden fazla alsaydi softmax olarak activation function alacaktik\n",
    "                                            # eger hic birsey yazmasak otomatikmen linear regresiion gibi bir deger alan bir ciktimiz ooacakti para gibi falan\n",
    "                                            # her bir laer icin farkli bir activation function secilebilir, best practice ile hangisinin daha iyi oldugunu bulabiliriz\n",
    "\n",
    "\n",
    "\n",
    "# burda activation function cesitleri var,\n",
    "   # 1- sigmoid = belli bir threshol degeri üstündekileri 1 yapiyor, altinda kalanlari 0 yapiyor\n",
    "   # 2- relu = eksili degerleri sifir aliyor ve pozitif degerlerde giderek büyüyebilir\n",
    "   # 3- tanh = belli bir deger üstündekileri 1 ve altindakileride -1 yapiyor\n",
    "   \n",
    "\n",
    "\n",
    "# burda Dense aslinda hidden layers'lari olustururken kullaniyoruz, ve fullyconnected kurmak icin bunlari kulaniyoruz\n",
    "\n",
    "opt = Adam(lr=0.002)   \n",
    "#buda önemli aslinda hatanin en minimum oldugu adim arligini gösteriyor, eger bunu cok kücük alirsa, minimum noktayi bulmasi uzun sürer\n",
    "# eger büyük alirsakta o minimum noktanin üstünden hep ziplar ve o noktaynin tam yerini bulmasi zor olur\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt, \n",
    "              loss=\"binary_crossentropy\",#bunun ekran görüntüsü vardi sigmoid var, (bir yerden sonrasi yukari, digerleri asagi olacak sekilde) ,binary model ile ugrastigimiz icin binary_crossentropy olani kullaniyoruz\n",
    "              #eger burda bir den fazla categori olsaydi categorical_crossentropy kliullanacaktik\n",
    "              metrics=[\"Recall\"])  # recall sectik,burda 1 olanlar önemliydi, onun icin recall sectik\n",
    "# Recall — the percentage of positive cases you caught\n",
    "# Recall, false negative’in gözardı edilemez olduğu durumlarda önemli bir metrik. recall = TP / TP +FN\n",
    "# Recall’a bakma sebebimiz tamamiyle paydadaki false negative’ler, yani hesabına devam ettiği tahmin edilen ve hesabını kapatan insanlar. \n",
    "# ve bence eger clasification problemi üzerine calisiyorsak, metrics='accuracy alabiliriz ama bir üst satirda oldugu gibi binary olunca ve 1 olan degerler \n",
    "# daha önemliyse recall'a da bakmak iyi olabilir\n",
    "\n",
    "\n",
    "\n",
    "Recall = # icin sunlari söyleyebilirim eger binary classification problemimiz varsa yani target features 0 veya 1 lerden olusuyorsa recall bize iyi bir Ansicht verebilir\n",
    "         # örnegin Churn analizi yaparkende bunu kullanmak daha mantikli, burda recall True Pozitif ve False Negatif degerleri önemli\n",
    "         # örnegin asagida Churn analizi icin True False ve True negatif degelreine bakalim\n",
    "         # elimizde olan secenekler \n",
    "         # ve bunlari degerlendirirken su iki kritere bakacagiz. dogru bildi mi? bilmedi mi?\n",
    "         # eger dogru bildiyse True koy ve dogru bildigi sey senin 1 dedigin sey ile ayniysa onada Positif koy,yani True positive\n",
    "         #  eger dogru bildigi sey senin 1 dedigin ile ayni degilse , \n",
    "         # ozaman dogru bildigi icin True koy ama 1 olan sey olmadigi icin yani 0 i oldugu icin bide Negatif koymaliyiz, yani True Negative\n",
    "         \n",
    "         #CHURN datasina göre bunlara verecegimiz isimler :\n",
    "         #   -gidene gitmis demek= Treu Positive\n",
    "         #   -gidene gitmemis demek= False Negative\n",
    "         #   -gitmeyene gitmis demek= False Posotive\n",
    "         #   -gitmeyene gitmemis demek= True Negative\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#burda iki tane hiddenlayer var, output hidden layer olarak sayilmiyor\n",
    "\n",
    "#inputta bizim feattureslrimiz\n",
    "\n",
    "# model.add(Dense(1, activation=\"sigmoid\"))  burda outputta sigmoid kullanmislar bunun classification oldugunu görüyoruz\n",
    "# burda Dense iki yapmadik, cünkü bize 1ler lazimdi 0lar lazim degil,yani setosa ve virginica gibi degil,0lari istemedik\n",
    "\n",
    "\n",
    "\n",
    "------------------\n",
    "# recall = TP / TP +FN   burda güzel bir detay farkettim, TP bizim Churn=ayrilma datamiza göre gidenleri 1 yani pozitif olarak bakacagiz\n",
    "# eger cikani dogru bilirse TP oluyor, eger \n",
    "# FN ise burda yanlis bilmis, neyi yanlis bilmis, birine 0 demis yani müsteri olarak kalmis demis, ama burdan anliyoruz ki bu müsteri gitmis\n",
    "# burda 1 olanlar önemli oldugu icin degerlendirmeye bakarken metrics = recall degerine bakacagiz,\n",
    "------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  classes=np.unique(y_train), #burda galiba kac class verecegimizi söylüyoruz\n",
    "                                                  y=y_train)\n",
    "\n",
    "class_weights = {0: class_weights[0], 1: class_weights[1]}\n",
    "class_weights\n",
    "\n",
    "ciktilari :  {0: 0.6278777731268314, 1: 2.454991816693944}\n",
    "\n",
    "# class_weight bunlar bunlarda onlarin balance'lik durumunu ortaya koyuyor sanirim\n",
    "# bu datamizda target features'imiz 0 yada 1 olarak degerler aliyor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x=X_train,\n",
    "          y=y_train,\n",
    "          validation_split=.1,\n",
    "          batch_size=128,   # batch_size ise, bizim verimizi modele kaclik paketler halinde verecegimizi gösteriyor, eger bu 128 ise datayi 128 e bölüp iteration sayisini buluyoruz\n",
    "          epochs=200,   # eger datamizi tamamen bastan sona bir kere modele verince 1 Epoch oluyor, burda datamizi 200 defa modele sokacagiz\n",
    "          verbose=1,\n",
    "          callbacks=[early_stop],\n",
    "          class_weight=class_weights) #buraya bu degiskeni atiyoruz, bu degiskenide yukarida tanimlamistik\n",
    "\n",
    "\n",
    "          #ve modeli fit ederken bu sekilde class_weight i parametre olarak veriyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor=\"val_loss\",   # neye bakarak early stopping yap demek icin, bu degere bakarak yapiyor,validation loss\n",
    "                           mode=\"auto\", #düsüklügemi göre mi yükseklige göre mi, yoksa  ben mi otomatik belirleyeyim diyor,yani hangi kritere göre durduraym\n",
    "                           verbose=1,\n",
    "                           patience=25)  # 25 degerden sonra rakam cok degismiyorsa,(peeyy-şıınss)\n",
    "#The patience is often set somewhere between 10 and 100 (10 or 20 is more common), \n",
    "#but it really depends on your dataset and network.\n",
    "\n",
    "# bir early stopping koyalim dedik\n",
    "\n",
    "# buraya her val_loss yazin deniyor, sadece loss girersen o düsecegi icin validation loss deniyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")  #0.5 threshold degeri olarak belirledik \n",
    "\n",
    "# binary calssification datasetlerinde predict yaparken istersek, bir threshold degeri belirleyip ona göre de predict yaptirabiliriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights   # ile egittigin modelin agirliklarina bakabiliyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model kaydetme ile ilgili bilgiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_churn.h5')   #model kaydetme bu sekilde yapiliyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ama bu yukarida yaptigimiz islemlemleri yani classfication problemini ML modelleri ilede yapabiliriz, \n",
    "# sonra hangisinin daha iyi olduguna bakabiliriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_churn.h5')   #model kaydetme bu sekilde yapiliyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor=\"val_loss\",   # neye bakarak early stopping yap demek icin, bu degere bakarak yapiyor,validation loss\n",
    "                           mode=\"auto\", #düsüklügemi göre mi yükseklige göre mi, yoksa  ben mi otomatik belirleyeyim diyor,yani hangi kritere göre durduraym\n",
    "                           verbose=1,\n",
    "                           patience=25) ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, \n",
    "              loss=\"binary_crossentropy\",#bunun ekran görüntüsü vardi sigmoid var, (bir yerden sonrasi yukari, digerleri asagi olacak sekilde) ,binary model ile ugrastigimiz icin binary_crossentropy olani kullaniyoruz\n",
    "              #eger burda bir den fazla categori olsaydi categorical_crossentropy kliullanacaktik\n",
    "              metrics=[\"Recall\"])  # recall sectik,burda 1 olanlar önemliydi, onun icin recall sectik\n",
    "# Recall — the percentage of positive cases you caught  ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor=\"val_loss\",   # , bu degere bakarak yapiyor,validation loss\n",
    "                           mode=\"auto\", #yükseklige göre mi, yoksa  ben mi otomatik belirleyeyim diyor,yani hangi kritere göre durduraym\n",
    "                           verbose=1,\n",
    "                           patience=25)\n",
    "model.compile(optimizer=opt, \n",
    "              loss=\"binary_crossentropy\",# (bir yerden sonrasi yukari, digerleri asagi olacak sekilde) ,binary model ile ugrastigimiz icin binary_crossentropy olani kullaniyoruz\n",
    "              #eger burda bir den fazla categori olsaydi categorical_crossentropy kliullanacaktik\n",
    "              metrics=[\"Recall\"])                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7c19a79b9aeb8b1cc18eda6778f62d726c8b19540b84d23ad80114035b2e0b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
